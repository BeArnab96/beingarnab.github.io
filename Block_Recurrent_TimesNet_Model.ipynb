{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNlIrbybq38dP0ZhT+cwk+P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BeArnab96/beingarnab.github.io/blob/gh-pages/Block_Recurrent_TimesNet_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR8yx9BXX4hF",
        "outputId": "53a78951-1035-4d80-80d4-fbcde495d679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting einops\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.7.0\n"
          ]
        }
      ],
      "source": [
        "! pip install einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import os, sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, random\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.ndimage import median_filter\n",
        "from einops import rearrange, repeat, einsum, reduce\n",
        "from einops.layers.torch import Rearrange\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from glob import glob\n",
        "import natsort\n",
        "import random\n",
        "import re"
      ],
      "metadata": {
        "id": "rco0-9FfYAZS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conv Blocks"
      ],
      "metadata": {
        "id": "zTz16jJvYFXx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Inception_Block_V1(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, final_shape=None, num_kernels=6, kernel_size=7, patch_size=4,\n",
        "                 init_weight=True):\n",
        "        super(Inception_Block_V1, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.num_kernels = num_kernels\n",
        "        kernels = []\n",
        "        for i in range(self.num_kernels):\n",
        "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=int(2 * i + 1), padding=int(i)))\n",
        "        self.kernels = nn.ModuleList(kernels)\n",
        "        if init_weight:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res_list = []\n",
        "        for i in range(self.num_kernels):\n",
        "            res_list.append(self.kernels[i](x))\n",
        "        res = torch.stack(res_list, dim=-1).mean(-1)\n",
        "        return res\n",
        "\n",
        "class Inception_Block_V2(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, final_shape=None, num_kernels=6, kernel_size=7, patch_size=4,\n",
        "                 init_weight=True):\n",
        "        super(Inception_Block_V2, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.num_kernels = num_kernels\n",
        "        kernels = []\n",
        "        for i in range(self.num_kernels // 2):\n",
        "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=[1, 2 * i + 3], padding=[0, i + 1]))\n",
        "            kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=[2 * i + 3, 1], padding=[i + 1, 0]))\n",
        "        kernels.append(nn.Conv2d(in_channels, out_channels, kernel_size=1))\n",
        "        self.kernels = nn.ModuleList(kernels)\n",
        "        if init_weight:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        res_list = []\n",
        "        for i in range(self.num_kernels + 1):\n",
        "            res_list.append(self.kernels[i](x))\n",
        "        res = torch.stack(res_list, dim=-1).mean(-1)\n",
        "        return res\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.fn(x)\n",
        "\n",
        "class ConvNeXT_Block(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_shape=None, num_kernels=6, kernel_size=7, patch_size=4,\n",
        "                 init_weight=True):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.patch_size = patch_size\n",
        "        self.final_shape = (10, 10) if final_shape is None else final_shape\n",
        "\n",
        "        self.patchifying_conv = nn.Conv2d(in_channels, out_channels, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "        self.depth_conv = nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, groups=out_channels,\n",
        "                                    padding='same')\n",
        "        self.layernorm = nn.LayerNorm(out_channels)\n",
        "\n",
        "        self.mixer_bottleneck = nn.Sequential(nn.Conv2d(out_channels, int(out_channels * 4), kernel_size=1),\n",
        "                                              nn.GELU(),\n",
        "                                              nn.Conv2d(int(4 * out_channels), out_channels, kernel_size=1))\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d(self.final_shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        patches = self.patchifying_conv(x)\n",
        "        depth_conv_emb = self.depth_conv(patches).permute(0, 2, 3, 1)\n",
        "        residual_emb = self.layernorm(depth_conv_emb).permute(0, 3, 1, 2) + patches\n",
        "\n",
        "        final_op = self.mixer_bottleneck(residual_emb)\n",
        "        final_op = self.pool(final_op)\n",
        "\n",
        "        return final_op\n",
        "\n",
        "class ResNeXT_Block(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_shape=None, num_kernels=6, kernel_size=3, patch_size=4,\n",
        "                 init_weight=True):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.bnorm1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.conv1 = nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=1, padding='same'),\n",
        "                                   nn.GELU(),\n",
        "                                   nn.BatchNorm2d(out_channels))\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, groups=out_channels, padding='same'),\n",
        "            nn.GELU(),\n",
        "            nn.BatchNorm2d(out_channels))\n",
        "        self.conv3 = nn.Sequential(nn.Conv2d(out_channels, in_channels, kernel_size=1, padding='same'),\n",
        "                                   nn.GELU(),\n",
        "                                   nn.BatchNorm2d(in_channels))\n",
        "        # self.pool = nn.AdaptiveAvgPool2d(self.final_shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.conv3(self.conv2(self.conv1(x)))\n",
        "\n",
        "class ConvMix_Block(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_shape=None, num_kernels=None, kernel_size=9, patch_size=7,\n",
        "                 init_weight=True):\n",
        "        super().__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        self.final_shape = (10, 10) if final_shape is None else final_shape\n",
        "\n",
        "        self.patchifying_conv = nn.Conv2d(in_channels, out_channels, kernel_size=patch_size, stride=patch_size)\n",
        "        self.act = nn.GELU()\n",
        "        self.bnorm1 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "        self.spatial_mixer = nn.Sequential(Residual(nn.Sequential(\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=kernel_size, groups=out_channels, padding='same'),\n",
        "            nn.GELU(),\n",
        "            nn.BatchNorm2d(out_channels))))\n",
        "\n",
        "        self.channel_mixer = nn.Sequential(nn.Conv2d(out_channels, out_channels, kernel_size=1),\n",
        "                                           nn.GELU(),\n",
        "                                           nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d(self.final_shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        patches = self.bnorm1(self.act(self.patchifying_conv(x)))\n",
        "        spatial_mix = self.spatial_mixer(patches)\n",
        "        channel_mix = self.channel_mixer(spatial_mix)\n",
        "        final_op = self.pool(channel_mix)\n",
        "\n",
        "        return final_op\n",
        "\n",
        "class ConvNeXT_multiscale_shared(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_shape=None, num_kernels=6, kernel_size=None,\n",
        "                 patch_size=[2, 4, 6], init_weight=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.num_kernels = num_kernels\n",
        "        self.patch_size = patch_size\n",
        "        self.final_shape = (10, 10) if final_shape is None else final_shape\n",
        "\n",
        "        patch_list = []\n",
        "        for i in range(len(patch_size)):\n",
        "            patch_list.append(\n",
        "                nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=patch_size[i], stride=patch_size[i]),\n",
        "                              # Patchify\n",
        "                              nn.BatchNorm2d(out_channels),\n",
        "                              nn.GELU()))\n",
        "\n",
        "        kernel_list = []\n",
        "        for j in range(num_kernels // 2):\n",
        "            kernel_list.append(nn.Sequential(\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size=[1, int(2 * j + 3)], groups=out_channels,\n",
        "                          padding=[0, j + 1]),  # Depthwise convolution\n",
        "                nn.Conv2d(out_channels, out_channels, kernel_size=[int(2 * j + 3), 1], groups=out_channels,\n",
        "                          padding=[j + 1, 0]),  # Inception Style\n",
        "                nn.BatchNorm2d(out_channels),\n",
        "                nn.Conv2d(out_channels, 4 * out_channels, kernel_size=1),  # Inverse Bottleneck\n",
        "                nn.GELU(),\n",
        "                nn.Conv2d(4 * out_channels, out_channels, kernel_size=1)))\n",
        "\n",
        "        self.patch_module_list = nn.ModuleList(patch_list)\n",
        "        self.kernel_module_list = nn.ModuleList(kernel_list)\n",
        "\n",
        "        # self.kernel_module_list = nn.ModuleList(kernel_list)\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d(self.final_shape)\n",
        "\n",
        "        # self.dim_proj = nn.Conv2d(out_channels*)\n",
        "\n",
        "        if init_weight:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        res_list = []\n",
        "        for i in range(len(self.patch_size)):\n",
        "\n",
        "            patches = self.patch_module_list[i](x)\n",
        "\n",
        "            patch_res_list = []\n",
        "            for j in range(self.num_kernels // 2):\n",
        "                patch_res_list.append(self.kernel_module_list[j](patches))\n",
        "\n",
        "            patch_res = torch.stack(patch_res_list, dim=-1).mean(-1) + patches\n",
        "            patch_res = self.pool(patch_res)\n",
        "            res_list.append(patch_res)\n",
        "\n",
        "        final_res = torch.stack(res_list, dim=-1).mean(-1)\n",
        "        return final_res\n",
        "\n",
        "class ConvNeXT_multiscale_independent(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_shape=None, num_kernels=6, kernel_size=None,\n",
        "                 patch_size=[2, 4, 6], init_weight=True):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.num_kernels = num_kernels\n",
        "        self.patch_size = patch_size\n",
        "        self.final_shape = (10, 10) if final_shape is None else final_shape\n",
        "\n",
        "        kernel_list = []\n",
        "        for i in range(len(patch_size)):\n",
        "            patch_list = [\n",
        "                nn.Sequential(nn.Conv2d(in_channels, out_channels, kernel_size=patch_size[i], stride=patch_size[i]),\n",
        "                              # Patchify\n",
        "                              nn.BatchNorm2d(out_channels),\n",
        "                              nn.GELU())]\n",
        "            for j in range(num_kernels // 2):\n",
        "                patch_list.append(nn.Sequential(\n",
        "                    nn.Conv2d(out_channels, out_channels, kernel_size=[1, int(2 * j + 3)], groups=out_channels,\n",
        "                              padding=[0, j + 1]),  # Depthwise convolution\n",
        "                    nn.Conv2d(out_channels, out_channels, kernel_size=[int(2 * j + 3), 1], groups=out_channels,\n",
        "                              padding=[j + 1, 0]),  # Inception Style\n",
        "                    nn.BatchNorm2d(out_channels),\n",
        "                    nn.Conv2d(out_channels, 4 * out_channels, kernel_size=1),  # Inverse Bottleneck\n",
        "                    nn.GELU(),\n",
        "                    nn.Conv2d(4 * out_channels, out_channels, kernel_size=1)))\n",
        "\n",
        "            patch_module_list = nn.ModuleList(patch_list)\n",
        "\n",
        "            kernel_list.append(patch_module_list)\n",
        "        self.kernel_module_list = nn.ModuleList(kernel_list)\n",
        "\n",
        "        self.pool = nn.AdaptiveAvgPool2d(self.final_shape)\n",
        "\n",
        "        # self.dim_proj = nn.Conv2d(out_channels*)\n",
        "\n",
        "        if init_weight:\n",
        "            self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        B, C, H, W = x.shape\n",
        "\n",
        "        res_list = []\n",
        "\n",
        "        for i in range(len(self.patch_size)):\n",
        "\n",
        "            patches = self.kernel_module_list[i][0](x)\n",
        "            patch_res_list = []\n",
        "\n",
        "            for j in range(self.num_kernels // 2):\n",
        "                patch_res_list.append(self.kernel_module_list[i][j + 1](patches))\n",
        "\n",
        "            patch_res = torch.stack(patch_res_list, dim=-1).mean(-1) + patches\n",
        "            patch_res = self.pool(patch_res)\n",
        "            res_list.append(patch_res)\n",
        "\n",
        "        final_res = torch.stack(res_list, dim=-1).mean(-1)\n",
        "        return final_res\n",
        "\n",
        "class SwinTransformer_Block(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, final_shape=None, num_kernels=6, kernel_size=7, patch_size=7,\n",
        "                 shift_size=None, dropout=0.1):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.patch_size = patch_size\n",
        "        self.shift_size = (patch_size // 2, patch_size // 2) if shift_size is None else shift_size\n",
        "        self.attn_dropout = dropout\n",
        "        self.proj_drop = dropout\n",
        "        self.projection = nn.Linear(out_channels, out_channels)\n",
        "\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.qkv_projection = nn.Linear(out_channels, int(out_channels * 3))\n",
        "\n",
        "        self.norm1 = nn.LayerNorm()\n",
        "        self.norm2 = nn.LayerNorm()\n",
        "\n",
        "        pass"
      ],
      "metadata": {
        "id": "GJXH-D2EYEe0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Timesnet feature extractor"
      ],
      "metadata": {
        "id": "26L52AhDYMGa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "class RoPE(nn.Module):\n",
        "\n",
        "    def __init__(self, dmodel):\n",
        "        super().__init__()\n",
        "        self.dmodel = dmodel\n",
        "        dims = torch.arange(self.dmodel // 2)\n",
        "        self.theta = torch.zeros((self.dmodel,))\n",
        "\n",
        "        self.theta[0::2] = 10000 ** (2 * dims / dmodel)\n",
        "        self.theta[1::2] = 10000 ** (2 * dims / dmodel)\n",
        "\n",
        "    def forward(self, x, timestamp):\n",
        "        B, T, D = x.shape\n",
        "        _, _ = timestamp.shape\n",
        "\n",
        "        xcos = x\n",
        "        xsin = torch.zeros_like(x)\n",
        "        xsin[:, :, 0::2] = -x[:, :, 1::2]\n",
        "        xsin[:, :, 1::2] = x[:, :, 0::2]\n",
        "\n",
        "        trig_args = torch.matmul(timestamp.reshape(B, T, 1).float(), self.theta.reshape(1, 1, -1).float())\n",
        "        sin_ = torch.sin(trig_args)\n",
        "        cos_ = torch.cos(trig_args)\n",
        "\n",
        "        rpos_emb = x * sin_ + x * cos_\n",
        "\n",
        "        return rpos_emb\n",
        "\n",
        "\n",
        "class TaskEmbedding(nn.Module):\n",
        "\n",
        "  def __init__(self, din, dmodel):\n",
        "\n",
        "    super().__init__()\n",
        "    self.dmodel = dmodel\n",
        "    self.din = din\n",
        "    self.embedding = nn.Linear(din,dmodel)\n",
        "\n",
        "  def forward(self, task_feats):\n",
        "\n",
        "    return self.embedding(task_feats)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2zYEy_TYCI9",
        "outputId": "8703be70-91e2-4c27-b559-ddd11615abd2"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py:125: UserWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\n",
            "  warnings.warn(\"Decorating classes is deprecated and will be disabled in \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def FFT_for_Period(x, k=2):\n",
        "    # [B, T, C]\n",
        "    T = x.shape[1]\n",
        "    xf = torch.fft.rfft(x, dim=1)\n",
        "    # find period by amplitudes\n",
        "    frequency_list = abs(xf).mean(0).mean(-1)\n",
        "    frequency_list[0] = 0\n",
        "    _, top_list = torch.topk(frequency_list, len(frequency_list))\n",
        "    top_list = top_list.detach().cpu().numpy()\n",
        "\n",
        "    actual_list = []\n",
        "    period_list = []\n",
        "    count = 0\n",
        "\n",
        "    while len(actual_list) < k and count < len(top_list):\n",
        "        if T // top_list[count] not in period_list:\n",
        "            period_list.append(T // top_list[count])\n",
        "            actual_list.append(top_list[count])\n",
        "        else:\n",
        "            pass\n",
        "        count += 1\n",
        "\n",
        "    actual_list = np.asarray(actual_list)\n",
        "\n",
        "    period = x.shape[1] // actual_list\n",
        "    return period, abs(xf).mean(-1)[:, actual_list]\n",
        "\n",
        "\n",
        "class TimesBlock(nn.Module):\n",
        "    def __init__(self, tblock_configs):\n",
        "        super(TimesBlock, self).__init__()\n",
        "\n",
        "        self.seq_len = tblock_configs['cycle_len']\n",
        "        self.k = tblock_configs['top_k']\n",
        "        self.conv_type = tblock_configs['conv_type']\n",
        "        self.dmodel = tblock_configs['dmodel']\n",
        "\n",
        "        if self.conv_type != 'ConvNeXT_MS':\n",
        "          in_c, out_c, fin_shape, num_k, k_size, p_size, init_w =  tblock_configs['conv_configs'][self.conv_type]['configs'][0]\n",
        "          in_c1, out_c1, fin_shape1, num_k1, k_size1, p_size1, init_w1 = tblock_configs['conv_configs'][self.conv_type]['configs'][1]\n",
        "        else:\n",
        "          in_c, out_c, fin_shape, num_k, k_size, p_size, init_w = tblock_configs['conv_configs'][self.conv_type]['configs'][0]\n",
        "\n",
        "        if self.conv_type == 'InceptionV1':\n",
        "            self.conv_net = nn.Sequential(Inception_Block_V1(in_c, out_c, fin_shape, num_k, k_size, p_size, init_w),\n",
        "                                          nn.GELU(),\n",
        "                                          Inception_Block_V1(in_c1, out_c1, fin_shape1, num_k1, k_size1, p_size1,\n",
        "                                                             init_w1))\n",
        "\n",
        "        elif self.conv_type == 'InceptionV2':\n",
        "            self.conv_net = nn.Sequential(Inception_Block_V2(in_c, out_c, fin_shape, num_k, k_size, p_size, init_w),\n",
        "                                          nn.GELU(),\n",
        "                                          Inception_Block_V2(in_c1, out_c1, fin_shape1, num_k1, k_size1, p_size1,\n",
        "                                                             init_w1))\n",
        "\n",
        "        elif self.conv_type == 'ConvNeXT':\n",
        "            self.conv_net = nn.Sequential(ConvNeXT_Block(in_c, out_c, fin_shape, num_k, k_size, p_size, init_w),\n",
        "                                          nn.GELU(),\n",
        "                                          ConvNeXT_Block(in_c1, out_c1, fin_shape1, num_k1, k_size1, p_size1, init_w1))\n",
        "\n",
        "        elif self.conv_type == 'ResNeXT':\n",
        "            self.conv_net = nn.Sequential(ResNeXT_Block(in_c, out_c, fin_shape, num_k, k_size, p_size, init_w),\n",
        "                                          nn.GELU(),\n",
        "                                          ResNeXT_Block(in_c1, out_c1, fin_shape1, num_k1, k_size1, p_size1, init_w1))\n",
        "\n",
        "        elif self.conv_type == 'ConvMix':\n",
        "            self.conv_net = nn.Sequential(ConvMix_Block(in_c, out_c, fin_shape, num_k, k_size, p_size, init_w),\n",
        "                                          nn.GELU(),\n",
        "                                          ConvMix_Block(in_c1, out_c1, fin_shape1, num_k1, k_size1, p_size1, init_w1))\n",
        "\n",
        "        elif self.conv_type == 'ConvNeXT_MS':\n",
        "            self.conv_net = ConvNeXT_multiscale_shared(in_c, out_c, fin_shape, num_k, k_size, p_size, init_w)\n",
        "\n",
        "        if self.conv_type in ['ConvNeXT', 'ConvNeXT_MS', 'ConvMix']:\n",
        "            h, w = tblock_configs['final_shape']\n",
        "            self.time_projection = nn.Linear(int(h * w), self.seq_len)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        B, T, D = x.size()\n",
        "        assert (T == self.seq_len), 'Time dimensions do not match'\n",
        "\n",
        "        period_list, period_weight = FFT_for_Period(x, self.k)\n",
        "\n",
        "        res = []\n",
        "        for i in range(self.k):\n",
        "            period = period_list[i]\n",
        "            # padding\n",
        "            if self.seq_len % period != 0:\n",
        "                length = ((self.seq_len // period) + 1) * period\n",
        "                padding = torch.zeros([x.shape[0], (length - self.seq_len), x.shape[2]]).to(x.device)\n",
        "                out = torch.cat([x, padding], dim=1)\n",
        "            else:\n",
        "                length = self.seq_len\n",
        "                out = x\n",
        "            # reshape\n",
        "            out = out.reshape(B, length // period, period, D).permute(0, 3, 1, 2).contiguous()\n",
        "\n",
        "            # 2D conv: from 1d Variation to 2d Variation\n",
        "            out = self.conv_net(out)\n",
        "            # reshape back\n",
        "            out = out.permute(0, 2, 3, 1).reshape(B, -1, D)\n",
        "\n",
        "            if self.conv_type in ['ConvNeXT', 'ConvNeXT_MS', 'ConvMix']:\n",
        "                out = self.time_projection(out.permute(0,2,1)).permute(0,2,1)\n",
        "\n",
        "            res.append(out[:, :self.seq_len, :])\n",
        "\n",
        "        res = torch.stack(res, dim=-1)\n",
        "        # adaptive aggregation\n",
        "        period_weight = F.softmax(period_weight, dim=1)\n",
        "        period_weight = period_weight.unsqueeze(1).unsqueeze(1).repeat(1, T, D, 1)\n",
        "        res = torch.sum(res * period_weight, -1)\n",
        "        # residual connection\n",
        "        res = res + x\n",
        "        return res\n",
        "\n",
        "\n",
        "class TimesNetModel(nn.Module):\n",
        "\n",
        "    def __init__(self, configs):\n",
        "        super().__init__()\n",
        "\n",
        "        self.seq_len = configs['cycle_len']\n",
        "        self.dmodel = configs['dmodel']\n",
        "        self.obs_din = configs['obs_din']\n",
        "        self.dec_din = configs['dec_din']\n",
        "        self.task_dim = configs['task_dim']\n",
        "\n",
        "        self.obs_model = nn.ModuleList([TimesBlock(configs)\n",
        "                                        for _ in range(configs['e_layers'])])\n",
        "\n",
        "        self.dec_model = nn.ModuleList([TimesBlock(configs)\n",
        "                                        for _ in range(configs['e_layers'])])\n",
        "\n",
        "        self.obs_val_embedding = nn.Linear(self.obs_din, self.dmodel)\n",
        "        self.rel_obs_emb = RoPE(self.dmodel)  # nn.Linear(self.seq_len, self.dmodel)\n",
        "\n",
        "        self.dec_val_embedding = nn.Linear(self.dec_din, self.dmodel)\n",
        "        self.rel_dec_emb = RoPE(self.dmodel)  # nn.Linear(self.seq_len, self.dmodel)\n",
        "\n",
        "        self.glob_fec_emb = nn.Embedding(10000, self.dmodel)\n",
        "\n",
        "        self.dropout = nn.Dropout(configs['emb_dropout'])\n",
        "\n",
        "        self.layer = configs['e_layers']\n",
        "\n",
        "        self.layer_norm_obs = nn.LayerNorm(configs['dmodel'])\n",
        "        self.layer_norm_dec = nn.LayerNorm(configs['dmodel'])\n",
        "\n",
        "        self.task_embedding = TaskEmbedding(self.task_dim, self.dmodel)\n",
        "\n",
        "    def forward(self, obs_vars, dec_vars, tsk_vars=None):\n",
        "        # dec_vars.shape = (B, T, 4)\n",
        "        # obs_vars.shape = (B, T, 6)\n",
        "\n",
        "        B, T, _ = obs_vars.shape\n",
        "\n",
        "        if tsk_vars is None:\n",
        "          tsk_emb = torch.zeros((B,1,self.dmodel))\n",
        "        else:\n",
        "          tsk_emb = self.task_embedding(tsk_vars)\n",
        "\n",
        "        obs_td = obs_vars[:, :, -2]\n",
        "        dec_td = dec_vars[:, :, -2]\n",
        "\n",
        "        obs_fec = obs_vars[:, 0, -1].int()\n",
        "        dec_fec = dec_vars[:, 0, -1].int()\n",
        "\n",
        "        obs_vars = self.obs_val_embedding(obs_vars[:, :, :-2])\n",
        "        dec_vars = self.dec_val_embedding(dec_vars[:, :, :-2])\n",
        "\n",
        "        obs_time_cum = torch.cumsum(obs_td, dim=-1)  # cumulative sum of time difference\n",
        "        dec_time_cum = torch.cumsum(dec_td, dim=-1)  # cumulative sum of time difference\n",
        "\n",
        "        # obs_td_mat = obs_td[:,None,:] - obs_td[:,:,None]  # obs_td_mat.shape = (B, T, T)\n",
        "        # dec_td_mat = dec_td[:,None,:] - dec_td[:,:,None]  # dec_td_mat.shape = (B, T, T)\n",
        "        # Series Stationarization\n",
        "        obs_means = obs_vars.mean(1, keepdim=True).detach()\n",
        "        obs_enc = obs_vars - obs_means\n",
        "        obs_stdev = torch.sqrt(torch.var(obs_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
        "        obs_enc /= obs_stdev\n",
        "\n",
        "        dec_means = dec_vars.mean(1, keepdim=True).detach()\n",
        "        dec_enc = dec_vars - dec_means\n",
        "        dec_stdev = torch.sqrt(torch.var(dec_enc, dim=1, keepdim=True, unbiased=False) + 1e-5)\n",
        "        dec_enc /= dec_stdev\n",
        "\n",
        "        # Value_embedding + global_pos_embedding\n",
        "        obs_emb = self.dropout(self.rel_obs_emb(obs_enc ,obs_time_cum) +  self.glob_fec_emb(obs_fec).reshape(B, -1, self.dmodel)) + tsk_emb.unsqueeze(1) # * self.rel_obs_emb(obs_td_mat)\n",
        "        dec_emb = self.dropout(self.rel_dec_emb(dec_enc ,dec_time_cum) + self.glob_fec_emb(dec_fec).reshape(B, -1, self.dmodel)) + tsk_emb.unsqueeze(1) # * self.rel_dec_emb(dec_td_mat)\n",
        "\n",
        "        # Apply TimesBlocks\n",
        "        for i in range(self.layer):\n",
        "            obs_emb = self.layer_norm_obs(self.obs_model[i](obs_emb))\n",
        "            dec_emb = self.layer_norm_dec(self.dec_model[i](dec_emb))\n",
        "\n",
        "        # De-stationarization\n",
        "\n",
        "        obs_out = obs_emb * (obs_stdev[:, 0, :].unsqueeze(1).repeat(1, self.seq_len, 1))\n",
        "        obs_out = obs_out + (obs_means[:, 0, :].unsqueeze(1).repeat(1, self.seq_len, 1))\n",
        "\n",
        "        dec_out = dec_emb * (dec_stdev[:, 0, :].unsqueeze(1).repeat(1, self.seq_len, 1))\n",
        "        dec_out = dec_out + (dec_means[:, 0, :].unsqueeze(1).repeat(1, self.seq_len, 1))\n",
        "\n",
        "        return obs_out, obs_td, dec_out, dec_td"
      ],
      "metadata": {
        "id": "xNrC09cEYO2M"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block Recurrent Transformer"
      ],
      "metadata": {
        "id": "QMicvFg-a4fk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, attention, num_heads, dmodel):\n",
        "        super().__init__()\n",
        "\n",
        "        self.att_ = attention\n",
        "        self.num_heads = num_heads\n",
        "        self.dmodel = dmodel\n",
        "\n",
        "\n",
        "        self.num_heads = num_heads\n",
        "        self.datt = int(dmodel * num_heads)\n",
        "\n",
        "        self.q_emb = nn.Linear(self.dmodel, self.datt)\n",
        "        self.v_emb = nn.Linear(self.dmodel, self.datt)\n",
        "        self.k_emb = nn.Linear(self.dmodel, self.datt)\n",
        "        self.out = nn.Linear(self.datt, self.dmodel)\n",
        "\n",
        "    def forward(self, q, k, v, attn_mask=None, tau=None, delta=None):\n",
        "        B, L, _ = q.shape\n",
        "        k_shape = k.shape\n",
        "\n",
        "        if len(k_shape) == 3:\n",
        "            _, S, _ = k.shape\n",
        "            key = self.k_emb(k).reshape(B, S, self.num_heads, self.dmodel)\n",
        "            value = self.v_emb(v).reshape(B, S, self.num_heads, self.dmodel)\n",
        "        elif len(k_shape) == 4:\n",
        "            _, S, T, _ = k.shape\n",
        "            key = self.k_emb(k).reshape(B, S, T, self.num_heads, self.dmodel).permute(0,1,3,2,4)\n",
        "            value = self.v_emb(v).reshape(B, S, T, self.num_heads, self.dmodel).permute(0,1,3,2,4)\n",
        "        query = self.q_emb(q).reshape(B, L, self.num_heads, self.dmodel)\n",
        "\n",
        "\n",
        "        V, attn = self.att_(query,\n",
        "                            key,\n",
        "                            value,\n",
        "                            attn_mask)\n",
        "\n",
        "        V = V.reshape(B, L, self.datt)\n",
        "        output = self.out(V)\n",
        "\n",
        "        return output, attn\n",
        "\n",
        "class FullAttention(nn.Module):\n",
        "\n",
        "    def __init__(self, trainable_scale=True, scale=None, output_attention=False, mask_flag=False, dropout=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.scale_train = trainable_scale\n",
        "        self.output_attention = output_attention\n",
        "        self.mask_flag = mask_flag\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        if trainable_scale:\n",
        "            if scale is None:\n",
        "                self.scale = nn.Parameter(torch.log2(torch.tensor(100**2-100).float()))\n",
        "            else:\n",
        "                self.scale = nn.Parameter(torch.log2(torch.tensor(scale**2-scale).float()))\n",
        "        else:\n",
        "            self.scale = None\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "\n",
        "        B, L, H, D = query.shape\n",
        "        v_shape = value.shape\n",
        "\n",
        "        if self.scale is None:\n",
        "            scale = 1 / math.sqrt(D)\n",
        "        else:\n",
        "            scale = self.scale\n",
        "            query = F.normalize(query, dim = 2)\n",
        "            key = F.normalize(key, dim = 2)\n",
        "\n",
        "        if len(v_shape) == 4:\n",
        "            _, S, _, _ = value.shape\n",
        "            scores = einsum(query, key,'b t1 h d, b t2 h d -> b h t1 t2')\n",
        "        elif len(v_shape) == 5:\n",
        "            _, S, _, T, _ = value.shape\n",
        "            scores = einsum(query, key, 'b l1 h d, b l2 h t d -> b h l1 l2 t').mean(-1)\n",
        "\n",
        "        if self.mask_flag:\n",
        "            scores = torch.tril(scores.reshape(-1,L,S)).reshape(B, H, L , S)\n",
        "\n",
        "\n",
        "            #scores = rearrange(scores, 'b h t1 t2 -> (b h) t1 t2')\n",
        "            #scores = torch.tril(scores)\n",
        "            #scores = rearrange(scores, '(b h) t1 t2 -> b h t1 t2')\n",
        "\n",
        "        scores = scores * scale\n",
        "        A = self.dropout(self.softmax(scores))\n",
        "        if len(v_shape) == 4:\n",
        "            V = einsum( A, value, 'b h t1 t2, b t2 h d -> b t1 h d')\n",
        "        elif len(v_shape) == 5:\n",
        "            V = einsum( A, value, 'b h t1 t2, b t2 h t d -> b t1 h d t').mean(-1)\n",
        "\n",
        "\n",
        "        if self.output_attention:\n",
        "            return (V.contiguous(), A)\n",
        "        else:\n",
        "            return (V.contiguous(), None)"
      ],
      "metadata": {
        "id": "uvgAweHsYQ8E"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block_Recurrent_Cell(nn.Module):\n",
        "\n",
        "    def __init__(self, attention_details, din, dout, gate_config='LSTM', gate_type='dual', vert_activation='leaky-relu',\n",
        "                 hor_activation='relu', d_ff=None, dropout=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        if din != dout:\n",
        "            self.transform_inp = nn.Linear(din, dout)\n",
        "\n",
        "        self.din = din\n",
        "        self.dmodel = dout\n",
        "\n",
        "        self.d_ff = int(4 * self.dmodel) if d_ff is None else d_ff\n",
        "\n",
        "        self.gate_config = gate_config\n",
        "        self.gate_type = gate_type\n",
        "\n",
        "        attention_list = attention_details['layers']\n",
        "        self.num_heads = attention_details['num_heads']\n",
        "\n",
        "        self.qs_hor = nn.Linear(dout, int(self.num_heads * self.dmodel))\n",
        "        self.qs_vert = nn.Linear(din, int(self.num_heads * self.dmodel))\n",
        "        self.qe_hor = nn.Linear(dout, int(self.num_heads * self.dmodel))\n",
        "        self.qe_vert = nn.Linear(din, int(self.num_heads * self.dmodel))\n",
        "\n",
        "        self.ks_emb = nn.Linear(dout, int(self.num_heads * self.dmodel))\n",
        "        self.ke_emb = nn.Linear(din, int(self.num_heads * self.dmodel))\n",
        "        self.vs_emb = nn.Linear(dout, int(self.num_heads * self.dmodel))\n",
        "        self.ve_emb = nn.Linear(din, int(self.num_heads * self.dmodel))\n",
        "\n",
        "        self.vert_self_att = attention_list[0]\n",
        "        self.vert_cross_att = attention_list[1]\n",
        "        self.hor_self_att = attention_list[2]\n",
        "        self.hor_cross_att = attention_list[3]\n",
        "\n",
        "        if vert_activation == 'relu':\n",
        "            self.vert_act = nn.ReLU()\n",
        "        elif vert_activation == 'leaky-relu':\n",
        "            self.vert_act = nn.LeakyReLU()\n",
        "        elif vert_activation == 'gelu':\n",
        "            self.vert_act = nn.GELU()\n",
        "\n",
        "        self.vert_projection = nn.Linear(int(2 * self.dmodel), self.dmodel)\n",
        "        self.vert_MLP = nn.Sequential(nn.Linear(self.dmodel, self.d_ff),\n",
        "                                      self.vert_act,\n",
        "                                      nn.Dropout(dropout),\n",
        "                                      nn.Linear(self.d_ff, self.dmodel))\n",
        "\n",
        "        if hor_activation == 'relu':\n",
        "            self.hor_act = nn.ReLU()\n",
        "        elif hor_activation == 'leaky-relu':\n",
        "            self.hor_act = nn.LeakyReLU()\n",
        "        elif hor_activation == 'gelu':\n",
        "            self.hor_act = nn.GELU()\n",
        "\n",
        "        if gate_config == 'LSTM':\n",
        "\n",
        "            if gate_type == 'dual':\n",
        "\n",
        "                self.inp_gate1 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                self.forget_gate1 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                self.z_emb1 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                torch.nn.init.normal_(self.inp_gate1.weight, mean=0.0, std=0.1)\n",
        "                torch.nn.init.normal_(self.inp_gate1.bias, mean=0.0, std=0.1)\n",
        "                torch.nn.init.normal_(self.forget_gate1.weight, mean=0.0, std=0.1)\n",
        "                torch.nn.init.normal_(self.forget_gate1.bias, mean=0.0, std=0.1)\n",
        "\n",
        "                self.inp_gate2 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                self.forget_gate2 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                self.z_emb2 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                torch.nn.init.normal_(self.inp_gate2.weight, mean=0.0, std=0.1)\n",
        "                torch.nn.init.normal_(self.inp_gate2.bias, mean=0.0, std=0.1)\n",
        "                torch.nn.init.normal_(self.forget_gate2.weight, mean=0.0, std=0.1)\n",
        "                torch.nn.init.normal_(self.forget_gate2.bias, mean=0.0, std=0.1)\n",
        "\n",
        "            elif gate_type == 'single' or gate_type == 'skip':\n",
        "\n",
        "                self.inp_gate1 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                self.forget_gate1 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                self.z_emb1 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                torch.nn.init.normal_(self.inp_gate1.weight, mean=0.0, std=0.1)\n",
        "                torch.nn.init.normal_(self.inp_gate1.bias, mean=0.0, std=0.1)\n",
        "                torch.nn.init.normal_(self.forget_gate1.weight, mean=0.0, std=0.1)\n",
        "                torch.nn.init.normal_(self.forget_gate1.bias, mean=0.0, std=0.1)\n",
        "\n",
        "        elif gate_config == 'Fixed':\n",
        "\n",
        "            if gate_type == 'single' or gate_type == 'skip':\n",
        "\n",
        "                self.z_emb1 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                self.bg1 = nn.Parameter(torch.randn(1, 1, self.dmodel))\n",
        "\n",
        "            elif gate_type == 'dual':\n",
        "\n",
        "                self.z_emb1 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                self.bg1 = nn.Parameter(torch.randn(1, 1, self.dmodel))\n",
        "\n",
        "                self.z_emb2 = nn.Linear(self.dmodel, self.dmodel)\n",
        "                self.bg2 = nn.Parameter(torch.randn(1, 1, self.dmodel))\n",
        "\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "        if gate_type == 'dual':\n",
        "\n",
        "            self.hor_projection = nn.Linear(int(2 * self.dmodel), self.dmodel)\n",
        "            self.hor_MLP = nn.Sequential(nn.Linear(self.dmodel, self.d_ff),\n",
        "                                         self.hor_act,\n",
        "                                         nn.Dropout(dropout),\n",
        "                                         nn.Linear(self.d_ff, self.dmodel))\n",
        "            self.hor_norm1 = nn.LayerNorm(self.dmodel)\n",
        "            self.hor_norm2 = nn.LayerNorm(self.dmodel)\n",
        "\n",
        "        elif gate_type == 'single':\n",
        "            self.hor_MLP = nn.Sequential(nn.Linear(int(2*self.dmodel), self.d_ff),\n",
        "                                         self.hor_act,\n",
        "                                         nn.Dropout(dropout),\n",
        "                                         nn.Linear(self.d_ff, self.dmodel))\n",
        "            self.hor_norm1 = nn.LayerNorm(self.dmodel)\n",
        "\n",
        "        elif gate_type == 'skip':\n",
        "            self.hor_projection = nn.Linear(int(2 * self.dmodel), self.dmodel)\n",
        "            self.hor_norm1 = nn.LayerNorm(self.dmodel)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.vert_norm1 = nn.LayerNorm(self.dmodel)\n",
        "        self.vert_norm2 = nn.LayerNorm(self.dmodel)\n",
        "\n",
        "        self.vert_satt_MLP = nn.Linear(int(self.num_heads*self.dmodel), self.dmodel)\n",
        "        self.vert_catt_MLP = nn.Linear(int(self.num_heads*self.dmodel), self.dmodel)\n",
        "        self.hor_satt_MLP = nn.Linear(int(self.num_heads*self.dmodel), self.dmodel)\n",
        "        self.hor_catt_MLP = nn.Linear(int(self.num_heads*self.dmodel), self.dmodel)\n",
        "\n",
        "    def forward(self, input_state, recurrent_state):\n",
        "\n",
        "        B, T, Din = input_state.shape\n",
        "\n",
        "        _, _, Dout = recurrent_state.shape\n",
        "\n",
        "        if Din != Dout:\n",
        "            residual = self.transform_inp(input_state)\n",
        "        else:\n",
        "            residual = input_state\n",
        "\n",
        "        # Vertical Direction\n",
        "\n",
        "        vert_self, vert_sa = self.vert_self_att(self.qe_vert(input_state).reshape(B, T, self.num_heads, self.dmodel),\n",
        "                                                self.ke_emb(input_state).reshape(B, T, self.num_heads, self.dmodel),\n",
        "                                                self.ve_emb(input_state).reshape(B, T, self.num_heads, self.dmodel))\n",
        "        vert_self = vert_self.reshape(B,T,-1)\n",
        "        vert_self = self.vert_satt_MLP(vert_self)\n",
        "\n",
        "        vert_cross, vert_ca = self.vert_cross_att(self.qs_vert(input_state).reshape(B, T, self.num_heads, self.dmodel),\n",
        "                                                  self.ks_emb(recurrent_state).reshape(B, T, self.num_heads,\n",
        "                                                                                       self.dmodel),\n",
        "                                                  self.vs_emb(recurrent_state).reshape(B, T, self.num_heads,\n",
        "                                                                                       self.dmodel))\n",
        "        vert_cross = vert_cross.reshape(B,T,-1)\n",
        "        vert_cross = self.vert_catt_MLP(vert_cross)\n",
        "\n",
        "        vert_embed = torch.cat((vert_self, vert_cross), dim=-1)\n",
        "        vert_embed = self.vert_norm1(self.dropout(self.vert_projection(vert_embed)) + residual)\n",
        "        vert_op = self.vert_norm2(self.vert_MLP(vert_embed) + vert_embed)\n",
        "\n",
        "        # Horizontal Direction\n",
        "\n",
        "        hor_self, hor_sa = self.hor_self_att(self.qs_hor(recurrent_state).reshape(B, T, self.num_heads, self.dmodel),\n",
        "                                             self.ks_emb(recurrent_state).reshape(B, T, self.num_heads, self.dmodel),\n",
        "                                             self.vs_emb(recurrent_state).reshape(B, T, self.num_heads, self.dmodel))\n",
        "        hor_self = hor_self.reshape(B,T,-1)\n",
        "        hor_self = self.hor_satt_MLP(hor_self)\n",
        "\n",
        "        hor_cross, hor_ca = self.hor_cross_att(self.qe_hor(recurrent_state).reshape(B, T, self.num_heads, self.dmodel),\n",
        "                                               self.ke_emb(input_state).reshape(B, T, self.num_heads, self.dmodel),\n",
        "                                               self.ve_emb(input_state).reshape(B, T, self.num_heads, self.dmodel))\n",
        "        hor_cross = hor_cross.reshape(B,T,-1)\n",
        "        hor_cross = self.vert_catt_MLP(hor_cross)\n",
        "\n",
        "        hor_embed = torch.cat((hor_self, hor_cross), dim=-1)\n",
        "\n",
        "        if self.gate_type == 'dual':\n",
        "\n",
        "            hor_embed = self.hor_norm1(self.hor_projection(hor_embed))\n",
        "\n",
        "            # gate 1\n",
        "\n",
        "            z_gate1 = self.tanh(self.z_emb1(hor_embed))\n",
        "            inp_gate_emb1 = self.sigmoid(self.inp_gate1(hor_embed) - 1)\n",
        "            for_gate_emb1 = self.sigmoid(self.forget_gate1(hor_embed) + 1)\n",
        "\n",
        "            next_state1 = recurrent_state * for_gate_emb1 + inp_gate_emb1 * z_gate1\n",
        "\n",
        "            # gate 2\n",
        "\n",
        "            next_state_emb = self.hor_norm2(self.hor_MLP(next_state1))\n",
        "            z_gate2 = self.tanh(self.z_emb2(next_state_emb))\n",
        "\n",
        "            inp_gate_emb2 = self.sigmoid(self.inp_gate2(next_state_emb) - 1)\n",
        "            for_gate_emb2 = self.sigmoid(self.forget_gate2(next_state_emb) + 1)\n",
        "\n",
        "            final_next_state = next_state1 * for_gate_emb2 + inp_gate_emb2 * z_gate2\n",
        "\n",
        "        elif self.gate_type == 'single':\n",
        "\n",
        "            hor_embed = self.hor_norm1(self.hor_MLP(hor_embed))\n",
        "\n",
        "            # gate 1\n",
        "\n",
        "            z_gate1 = self.tanh(self.z_emb1(hor_embed))\n",
        "            inp_gate_emb1 = self.sigmoid(self.inp_gate1(hor_embed) - 1)\n",
        "            for_gate_emb1 = self.sigmoid(self.forget_gate1(hor_embed) + 1)\n",
        "\n",
        "            final_next_state = recurrent_state * for_gate_emb1 + inp_gate_emb1 * z_gate1\n",
        "\n",
        "        elif self.gate_type == 'skip':\n",
        "\n",
        "            hor_embed = self.hor_norm1(self.hor_projection(hor_embed))\n",
        "\n",
        "            # gate 1\n",
        "\n",
        "            z_gate1 = self.tanh(self.z_emb1(hor_embed))\n",
        "            inp_gate_emb1 = self.sigmoid(self.inp_gate1(hor_embed) - 1)\n",
        "            for_gate_emb1 = self.sigmoid(self.forget_gate1(hor_embed) + 1)\n",
        "\n",
        "            final_next_state = recurrent_state * for_gate_emb1 + inp_gate_emb1 * z_gate1\n",
        "\n",
        "        vert_outputs = (vert_op, vert_sa, vert_ca)\n",
        "        hor_outputs = (final_next_state, hor_sa, hor_ca)\n",
        "\n",
        "        return vert_outputs, hor_outputs"
      ],
      "metadata": {
        "id": "KiB9IXHKa7n0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Block_Recurrent_Transformer_Layer(nn.Module):\n",
        "\n",
        "  def __init__(self, cell_config, max_state_len = 10000, dropout=0.1, return_sequence = True):\n",
        "    super().__init__()\n",
        "\n",
        "    self.din = cell_config['brt_din']\n",
        "    self.dout = cell_config['brt_dout']\n",
        "    self.dmodel = self.dout\n",
        "\n",
        "    #self.num_cells = cell_config['num_cells']\n",
        "    self.return_sequence = return_sequence\n",
        "\n",
        "    self.cell_gate_config = cell_config['gate_config']\n",
        "    self.cell_gate_type = cell_config['gate_type']\n",
        "    self.cell_vert_act = cell_config['vert_activation']\n",
        "    self.cell_hor_act = cell_config['hor_activation']\n",
        "    self.cell_dff = int(4*self.dmodel) if cell_config['d_ff'] is None else cell_config['d_ff']\n",
        "    self.attention_details = cell_config['attention_details']\n",
        "\n",
        "\n",
        "    self.state_rope = RoPE(self.dmodel)\n",
        "\n",
        "    self.BRCell = Block_Recurrent_Cell(self.attention_details,\n",
        "                                       self.din,\n",
        "                                       self.dmodel,\n",
        "                                       self.cell_gate_config,\n",
        "                                       self.cell_gate_type,\n",
        "                                       self.cell_vert_act,\n",
        "                                       self.cell_hor_act,\n",
        "                                       self.cell_dff, dropout)\n",
        "\n",
        "  def forward(self, x_seq, initial_state = None):\n",
        "\n",
        "    # x_seq.shape = B x num_cells x T x D\n",
        "    # initial_state.shape = B x T_state x D\n",
        "    #B, _, T, _ = obs_seq\n",
        "    #_, _, _, _ = dec_seq\n",
        "\n",
        "    B, num_cells, T, Din = x_seq.shape\n",
        "\n",
        "    if initial_state is not None:\n",
        "      _, T_state, _ = initial_state.shape\n",
        "      assert T_state==T, 'state and input time dimensions do not match'\n",
        "    else:\n",
        "      initial_state = torch.randn((B,T,self.dmodel), requires_grad=False)\n",
        "\n",
        "    initial_state = self.state_rope(initial_state, torch.arange(T).reshape(1,-1).repeat(B, 1))\n",
        "\n",
        "    output_list = torch.empty((B,num_cells,T,self.dmodel))\n",
        "    state_list = torch.empty((B,num_cells,T,self.dmodel))\n",
        "\n",
        "    vert_att_list = []\n",
        "    hor_att_list = []\n",
        "\n",
        "    for cell in range(num_cells):\n",
        "\n",
        "      next_output, next_state = self.BRCell(x_seq[:,cell,:,:], initial_state)\n",
        "\n",
        "      output_list[:,cell] = next_output[0]\n",
        "      state_list[:,cell] = next_state[0]\n",
        "\n",
        "      vert_att_list.append((next_output[1], next_output[2]))\n",
        "      hor_att_list.append((next_state[1], next_state[2]))\n",
        "\n",
        "      initial_state = self.state_rope(next_state[0], torch.arange(T).reshape(1,-1).repeat(B, 1)) #+ self.state_embed(torch.arange(T)).reshape(1,T,self.dmodel)\n",
        "      #initial_state = initial_state + self.state_embed(torch.arange(T)).reshape(1,T,self.dmodel)\n",
        "\n",
        "    if self.return_sequence:\n",
        "      return output_list, state_list, vert_att_list, hor_att_list\n",
        "    else:\n",
        "      return output_list[:,-1,:,:], state_list[:,-1,:,:], vert_att_list[-1], hor_att_list[-1]"
      ],
      "metadata": {
        "id": "AiVUaARFa-oD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Block Causal Decoder"
      ],
      "metadata": {
        "id": "65nM7DUzbDWy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, configs):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.att_heads = configs['dec_att_heads']\n",
        "        self.dmodel = configs['dmodel']\n",
        "        d_ff = configs['dec_d_ff'] or 4 * self.dmodel\n",
        "\n",
        "        self.self_attn = AttentionLayer(FullAttention(trainable_scale=True,\n",
        "                                                      scale = configs['num_cells'],\n",
        "                                                      mask_flag = True),\n",
        "                                        num_heads=self.att_heads,\n",
        "                                        dmodel=self.dmodel)\n",
        "\n",
        "        self.cross_attn = AttentionLayer(FullAttention(trainable_scale=True,\n",
        "                                                       mask_flag=True,\n",
        "                                                       scale = configs['num_cells']),\n",
        "                                         num_heads=self.att_heads,\n",
        "                                         dmodel=self.dmodel)\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=int(2*self.dmodel), out_channels=d_ff, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=self.dmodel, kernel_size=1)\n",
        "        self.norm1 = nn.LayerNorm(self.dmodel)\n",
        "        self.norm2 = nn.LayerNorm(self.dmodel)\n",
        "        self.norm3 = nn.LayerNorm(self.dmodel)\n",
        "        self.dropout = nn.Dropout(configs['dec_dropout'])\n",
        "        self.activation = nn.ReLU() if configs['dec_act'] == 'relu' else nn.GELU()\n",
        "\n",
        "    def forward(self, Q, state):\n",
        "\n",
        "        qself, Aself = self.self_attn(Q, Q, Q)\n",
        "        qself = self.dropout(qself)\n",
        "        qcross, Across = self.cross_attn(Q, state, state)\n",
        "        qcross = self.dropout(qcross)\n",
        "        qembed = torch.concat((self.norm1(qself + Q), self.norm2(qcross + Q)), dim=-1)\n",
        "\n",
        "        qout = self.conv2(self.dropout(self.activation(self.conv1(qembed.transpose(-1, 1))))).transpose(-1, 1)\n",
        "\n",
        "        return self.norm3(qout + Q)\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, configs):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.dmodel = configs['dmodel']\n",
        "        self.num_layers = configs['num_decoder_layers']\n",
        "        self.dout = configs['dec_dout']\n",
        "\n",
        "        self.layers = nn.ModuleList()\n",
        "        for l in range(self.num_layers):\n",
        "            self.layers.append(DecoderLayer(configs))\n",
        "\n",
        "        self.norm = nn.LayerNorm(self.dmodel)\n",
        "        self.projection = nn.Linear(self.dmodel, self.dout)\n",
        "\n",
        "        #self.input_embedding = RoPE(self.dmodel)\n",
        "        #self.cross_embedding = RoPE(int(self.state_seq_len*self.dmodel))\n",
        "\n",
        "    def forward(self, x, cross):\n",
        "\n",
        "        B, L, D = x.shape\n",
        "        _, _, T, _ = cross.shape\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, cross)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            x = self.norm(x)\n",
        "\n",
        "        if self.projection is not None:\n",
        "            x = self.projection(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "vyNpgMZ1bBLy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder_SSL(nn.Module):\n",
        "\n",
        "    def __init__(self, model_config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_cells = model_config['num_cells']\n",
        "        self.dmodel = model_config['dmodel']\n",
        "        #self.din = model_config['din']\n",
        "        self.dout = model_config['dout']\n",
        "        self.encoder_layers = model_config['recurrent_encoder_layers']\n",
        "\n",
        "        self.feat_ex = TimesNetModel(model_config)\n",
        "\n",
        "        self.encoder_layer = Block_Recurrent_Transformer_Layer(model_config)\n",
        "\n",
        "        self.obs_rope = RoPE(self.dmodel)\n",
        "        self.dec_rope = RoPE(self.dmodel)\n",
        "\n",
        "        self.out_MLP = nn.Sequential(nn.Linear(self.dmodel, int(4*self.dout)),\n",
        "                                     nn.LeakyReLU(0.05),\n",
        "                                     nn.Linear(int(4*self.dout), self.dout))\n",
        "\n",
        "        #self.glob_pos_obs_emb = nn.Embedding(self.num_cells, self.dmodel)\n",
        "\n",
        "    def forward(self, obs, dec, tsk = None, init_states=None):\n",
        "\n",
        "        # init_state.shape = B, T, dmodel\n",
        "\n",
        "        # Raw observation and control data. B:batch_size , L: number of cells, T: cycle_length\n",
        "        B, L, T, Dobs = obs.shape\n",
        "        _, _, _, Ddec = dec.shape\n",
        "\n",
        "        if tsk is not None:\n",
        "          _, Dtsk = tsk.shape\n",
        "\n",
        "        # Define initial states for each encoder layer - init_states needs to be a list of init_states for each recurrent encoder layer\n",
        "\n",
        "        #if init_states == None:\n",
        "        #    init_states = [None]*self.encoder_layers\n",
        "        #elif len(init_states) != self.encoder_layers:\n",
        "        #    init_states = [init_states]*self.encoder_layers\n",
        "\n",
        "        # Feature extraction using TimesNet\n",
        "        # We have two TimesNet networks - one for obs and one for dec\n",
        "        # The same two models are shared for all the cells.\n",
        "        # (B, L, T, Dobs), (B, L, T, Ddec) -> (B, L, T, Dmodel), (B, L, T, Dmodel)\n",
        "\n",
        "        obs_ = obs.reshape(int(B*L), T, -1)\n",
        "        dec_ = dec.reshape(int(B*L), T, -1)\n",
        "\n",
        "        if tsk is not None:\n",
        "          tsk_ = tsk.unsqueeze(1).repeat(1,L,1).reshape(int(B*L),-1)\n",
        "        else:\n",
        "          tsk_ = None\n",
        "\n",
        "\n",
        "        obs_out, obs_td, dec_out, dec_td = self.feat_ex(obs_,dec_, tsk_)\n",
        "\n",
        "\n",
        "        # The understated lines represent the incorporation of RoPE in obs and dec states following timesnet processing.\n",
        "        # This goes into the recurrent encoder\n",
        "        obs_out = self.obs_rope(obs_out, torch.cumsum(obs_td, dim = -1)).reshape(B,L,T,-1)\n",
        "        dec_out = self.dec_rope(dec_out, torch.cumsum(dec_td, dim = -1)).reshape(B,L,T,-1)\n",
        "\n",
        "        xout = torch.concat((obs_out, dec_out), dim = -1) # (B, L, T, D), (B, L, T, D) -> (B, L T, 2*D)\n",
        "\n",
        "        ops, states, _, _ = self.encoder_layer(xout, init_states) # except first cycle, all other cycles will have a non random init_state cached from the previous cycle\n",
        "        output = self.out_MLP(ops) # (B,L,T,D) - > (B,L,T, Dout)\n",
        "\n",
        "        return output, states"
      ],
      "metadata": {
        "id": "QMc1TuY-bGOt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, model_config):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_cells = model_config['num_cells']\n",
        "        self.dmodel = model_config['dmodel']\n",
        "        #self.max_cycles = model_config['max_cycles']\n",
        "        self.d_cap = model_config['cap_dim']\n",
        "        self.cycle_len = model_config['cycle_len']\n",
        "\n",
        "\n",
        "        self.SSL_encoder = Encoder_SSL(model_config)\n",
        "        self.decoder = Decoder(model_config)\n",
        "\n",
        "        self.cap_rope_emb = RoPE(self.dmodel)\n",
        "        self.state_rope_emb = RoPE(int(self.dmodel*self.cycle_len))\n",
        "\n",
        "        #self.cap_global_pos_emb = nn.Embedding(self.max_cycles,self.dmodel)\n",
        "        #self.state_global_pos_emb = nn.Embedding(self.max_cycles, int(self.dmodel*self.cycle_len))\n",
        "\n",
        "        self.cap_val_emb = nn.Linear(self.d_cap, self.dmodel)\n",
        "\n",
        "    def forward(self, obs, dec, cap, tsk = None, initial_state=None):\n",
        "\n",
        "        B, Nc, L, Do = obs.shape\n",
        "        _, _, _, Du = dec.shape\n",
        "        _, _, Dc = cap.shape\n",
        "\n",
        "        ssl_output, ssl_states = self.SSL_encoder(obs, dec, tsk, initial_state)\n",
        "\n",
        "        cap_cycle_index = cap[:,:,-1].int()\n",
        "        cap_emb = self.cap_rope_emb(self.cap_val_emb(cap[:,:,0:-1]), cap_cycle_index) #+ self.cap_global_pos_emb(cap_cycle_index)\n",
        "\n",
        "        states_ = ssl_states.reshape(B, Nc, -1)\n",
        "        dec_state_emb = self.state_rope_emb(states_, cap_cycle_index-1) #+ self.state_global_pos_emb(cap_cycle_index-1)\n",
        "\n",
        "        cap_next = self.decoder(cap_emb, dec_state_emb.reshape(B, Nc, L, -1))\n",
        "\n",
        "        return cap_next, ssl_output, ssl_states"
      ],
      "metadata": {
        "id": "MjqpDVYNbJJ8"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = 10\n",
        "w = 10\n",
        "\n",
        "model_config = {\n",
        "                # Model:\n",
        "                  'num_cells':50,'dmodel':32,'cap_dim':1,'cycle_len':100,\n",
        "\n",
        "                  # Encoder_SSL:\n",
        "                    'dout':3,'recurrent_encoder_layers':1,\n",
        "\n",
        "                    # TimesNetModel:\n",
        "                      'obs_din':4, 'dec_din':2, 'emb_dropout':0.1, 'e_layers':2,'task_dim':11,\n",
        "\n",
        "                      # TimeBlock:\n",
        "                        'top_k':5, 'conv_type':'InceptionV2', 'final_shape':(10,10),\n",
        "                        'conv_configs':{'InceptionV1':{ 'num_conv_blocks':2,\n",
        "                                                      'conv_layer_activation':'gelu',\n",
        "                                                      'configs': [(32, 128, None, 6, None, None, True),\n",
        "                                                                  (128, 32, None, 6, None, None, True)]},\n",
        "                                      'InceptionV2':{ 'num_conv_blocks':2,\n",
        "                                                      'conv_layer_activation':'gelu',\n",
        "                                                      'configs': [(32, 128, None, 6, None, None, True),\n",
        "                                                                  (128, 32, None, 6, None, None, True)]},\n",
        "                                      'ConvNeXT':{ 'num_conv_blocks':2,\n",
        "                                                    'conv_layer_activation':'gelu',\n",
        "                                                    'configs': [(32, 128, (h,w), None, 7, 4, True),\n",
        "                                                                (128, 32, (h,w), None, 7, 4, True)]},\n",
        "                                      'ResNeXT':{'num_conv_blocks':2,\n",
        "                                                    'conv_layer_activation':'gelu',\n",
        "                                                    'configs': [(32, 128, None, None, 3, None, True),\n",
        "                                                                (128, 32, None, None, 3, None, True)]},\n",
        "                                      'ConvMix':{'num_conv_blocks':2,\n",
        "                                                    'conv_layer_activation':'gelu',\n",
        "                                                    'configs': [(32, 128, (h,w), None, 7, 8, True),\n",
        "                                                                (128, 32, (h,w), None, 7, 2, True)]},\n",
        "                                      'ConvNeXT_MS':{'num_conv_blocks':1,\n",
        "                                                    'conv_layer_activation':'gelu',\n",
        "                                                    'configs': [(32, 32, (h,w), 6, 8, [2,5], True)]  }\n",
        "                                      },\n",
        "\n",
        "                    # Block_Recurrent_Transformer_Layer:\n",
        "                        'brt_din':64, 'brt_dout':32, 'gate_config':'LSTM', 'gate_type':'single','vert_activation':'gelu','hor_activation':'gelu','d_ff':None,\n",
        "                        'attention_details': {'num_heads':8,\n",
        "                                              'layers':[FullAttention(scale = None,\n",
        "                                                                      output_attention = False,\n",
        "                                                                      mask_flag = False,\n",
        "                                                                      dropout = 0.1),\n",
        "                                                        FullAttention(scale = None,\n",
        "                                                                      output_attention = False,\n",
        "                                                                      mask_flag = False,\n",
        "                                                                      dropout = 0.1),\n",
        "                                                        FullAttention(scale = None,\n",
        "                                                                      output_attention = False,\n",
        "                                                                      mask_flag = False,\n",
        "                                                                      dropout = 0.1),\n",
        "                                                        FullAttention(scale = None,\n",
        "                                                                      output_attention = False,\n",
        "                                                                      mask_flag = False,\n",
        "                                                                      dropout = 0.1)],\n",
        "                                              },\n",
        "\n",
        "                  # Decoder:\n",
        "                    'num_decoder_layers':2, 'dec_dout':1,\n",
        "\n",
        "                    # Decoder_layer:\n",
        "                      'dec_att_heads':8, 'dec_d_ff':None, 'dec_dropout': 0.2, 'dec_act':'gelu'\n",
        "                }"
      ],
      "metadata": {
        "id": "AeQxRyukbLO0"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "battery_model = Model(model_config)"
      ],
      "metadata": {
        "id": "dZsAgiOUbkJj"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "obs = torch.randn(1, 50, 100, 6)\n",
        "obs[:,:,:,-1] = torch.arange(50).unsqueeze(0).unsqueeze(2).repeat(1,1,100).int()\n",
        "dec = torch.randn(1, 50, 100, 4)\n",
        "dec[:,:,:,-1] = torch.arange(50).unsqueeze(0).unsqueeze(2).repeat(1,1,100).int()\n",
        "tsk = torch.randn(1, 11)\n",
        "cap = torch.randn(1, 50, 2)\n",
        "cap[:,:,-1] = torch.arange(50).unsqueeze(0).repeat(1,1).int()\n",
        "init_state = torch.randn(1, 100, 32)\n",
        "\n",
        "cnext, ssl_op, ssl_st = battery_model(obs, dec, cap, tsk, init_state)"
      ],
      "metadata": {
        "id": "EVjakHP3bn2-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_parameters = sum(p.numel() for p in battery_model.parameters())\n",
        "\n",
        "print(\"The number of trainable parameters is\", num_parameters)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zx4xRJjSbrGi",
        "outputId": "1950bc34-c52f-4124-9834-d5904a8d91c3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of trainable parameters is 1662780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rn761DXDeTkC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}